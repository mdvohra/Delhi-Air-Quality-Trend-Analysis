{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PktaPOEoaO5",
        "outputId": "1c43ca17-681c-4434-da62-f479a4986447"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "Can only use .dt accessor with datetimelike values",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m data_link \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mSandipan\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFinal\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[39m# Calculate and save monthly averages for each attribute\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m monthly_averages \u001b[39m=\u001b[39m calculate_monthly_averages(data_link)\n\u001b[0;32m     24\u001b[0m save_to_csv(monthly_averages, \u001b[39m\"\u001b[39m\u001b[39mDTU.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mcalculate_monthly_averages\u001b[1;34m(data_link)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_monthly_averages\u001b[39m(data_link):\n\u001b[0;32m      4\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data_link, parse_dates\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFrom Date\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mFrom Date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     attributes \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPM2.5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPM10\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNO2\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTemp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRH\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m     monthly_averages \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m'\u001b[39m: df[\u001b[39m'\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()})\n",
            "File \u001b[1;32mc:\\m_pf\\anaconda\\envs\\test\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n",
            "File \u001b[1;32mc:\\m_pf\\anaconda\\envs\\test\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
            "File \u001b[1;32mc:\\m_pf\\anaconda\\envs\\test\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39melif\u001b[39;00m is_period_dtype(data\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 580\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_monthly_averages(data_link):\n",
        "    df = pd.read_csv(data_link, parse_dates=['From Date'])\n",
        "    df['Month'] = df['From Date'].dt.strftime('%Y-%m')\n",
        "\n",
        "    attributes = ['Latitude','Longitude','PM2.5', 'PM10', 'NO2','Temp', 'RH']\n",
        "\n",
        "    monthly_averages = pd.DataFrame({'Month': df['Month'].unique()})\n",
        "    for attribute in attributes:\n",
        "        attribute_avg = df.groupby(['Month'])[attribute].mean().reset_index()\n",
        "        monthly_averages = pd.merge(monthly_averages, attribute_avg, on='Month', how='left', suffixes=('', f'_{attribute}'))\n",
        "\n",
        "    return monthly_averages\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    data.to_csv(filename, index=False)\n",
        "\n",
        "# Link to your data file\n",
        "data_link = r\"D:\\Sandipan\\Final\\1.csv\"\n",
        "\n",
        "# Calculate and save monthly averages for each attribute\n",
        "monthly_averages = calculate_monthly_averages(data_link)\n",
        "save_to_csv(monthly_averages, \"DTU.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_monthly_averages(data_link):\n",
        "    df = pd.read_csv(data_link, parse_dates=['From Date'], dayfirst=True)  # Parse dates correctly\n",
        "    df['Month'] = df['From Date'].dt.strftime('%Y-%m')\n",
        "\n",
        "    attributes = ['Latitude','Longitude','PM2.5', 'PM10', 'NO2','Temp', 'RH']\n",
        "\n",
        "    monthly_averages = pd.DataFrame({'Month': df['Month'].unique()})\n",
        "    for attribute in attributes:\n",
        "        attribute_avg = df.groupby(['Month'])[attribute].mean().reset_index()\n",
        "        monthly_averages = pd.merge(monthly_averages, attribute_avg, on='Month', how='left', suffixes=('', f'_{attribute}'))\n",
        "\n",
        "    return monthly_averages\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    data.to_csv(filename, index=False)\n",
        "\n",
        "# Link to your data file\n",
        "data_link = r\"D:\\Sandipan\\Final\\5.csv\"\n",
        "\n",
        "# Calculate and save monthly averages for each attribute\n",
        "monthly_averages = calculate_monthly_averages(data_link)\n",
        "save_to_csv(monthly_averages, \"Sirifort.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6nzuaxQqvnM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_yearly_combined_csv(station_files):\n",
        "    combined_data = pd.DataFrame()\n",
        "\n",
        "    for station_file in station_files:\n",
        "        # Read the station data CSV\n",
        "        df = pd.read_csv(station_file)\n",
        "\n",
        "        # Extract the year from the 'Month' column\n",
        "        df['Year'] = df['Month'].str[:4]\n",
        "\n",
        "        # Append the data to the combined DataFrame\n",
        "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
        "\n",
        "    # Group the combined data by year\n",
        "    grouped_data = combined_data.groupby('Year')\n",
        "\n",
        "    # Create separate CSV files for each year\n",
        "    for year, year_data in grouped_data:\n",
        "        year_filename = f\"{year}_combined_data.csv\"\n",
        "        year_data.to_csv(year_filename, index=False)\n",
        "\n",
        "# List of CSV files for different stations\n",
        "station_files = ['/content/Amritsar_averages.csv', '/content/Bhatinda_averages.csv', '/content/Jalandhar_averages.csv', '/content/Ludhiana_averages.csv', '/content/Patiala_averages.csv']\n",
        "\n",
        "# Create separate CSV files for each year\n",
        "create_yearly_combined_csv(station_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qie3XD8Z1l_c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_yearly_combined_csv(station_files):\n",
        "    combined_data = pd.DataFrame()\n",
        "\n",
        "    for station_file in station_files:\n",
        "        # Read the station data CSV\n",
        "        df = pd.read_csv(station_file)\n",
        "\n",
        "        # Extract the year from the 'Month' column\n",
        "        df['Year'] = df['Month'].str[:4]\n",
        "\n",
        "        # Append the data to the combined DataFrame\n",
        "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
        "\n",
        "    # Group the combined data by year\n",
        "    grouped_data = combined_data.groupby('Year')\n",
        "\n",
        "    # Create separate CSV files for each year\n",
        "    for year, year_data in grouped_data:\n",
        "        year_filename = f\"{year}_combined_data.csv\"\n",
        "        year_data.to_csv(year_filename, index=False)\n",
        "\n",
        "# List of CSV files for different stations\n",
        "station_files = ['/content/Amritsar_averages.csv', '/content/Bhatinda_averages.csv', '/content/Jalandhar_averages.csv', '/content/Ludhiana_averages.csv', '/content/Patiala_averages.csv']\n",
        "\n",
        "# Create separate CSV files for each year\n",
        "create_yearly_combined_csv(station_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZRv5sTy3K69"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Replace this with the path to your folder containing Excel files\n",
        "folder_path = '/path/to/your/excel/files'\n",
        "\n",
        "# Function to convert the date format\n",
        "def convert_date(date_str):\n",
        "    old_date = datetime.strptime(date_str, '%d-%m-%Y %H:%M')\n",
        "    new_date = old_date.strftime('%d/%m/%Y')\n",
        "    return new_date\n",
        "\n",
        "# Process each Excel file in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.xlsx'):  # Adjust if your files have a different extension\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        \n",
        "        # Read the Excel file\n",
        "        df = pd.read_excel(file_path)\n",
        "        \n",
        "        # Convert the 'From Date' column\n",
        "        df['From Date'] = df['From Date'].apply(convert_date)\n",
        "        \n",
        "        # Save the modified DataFrame back to the Excel file\n",
        "        df.to_excel(file_path, index=False)\n",
        "        \n",
        "        print(f\"Converted dates in {file_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
